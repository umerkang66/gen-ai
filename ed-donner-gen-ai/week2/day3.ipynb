{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
   "metadata": {},
   "source": [
    "## Day 3 - Conversational AI - aka Chatbot!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyDW\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful, funny and witty assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
   "metadata": {},
   "source": [
    "### Please read this! A change from the video:\n",
    "\n",
    "In the video, I explain how we now need to write a function called:\n",
    "\n",
    "`chat(message, history)`\n",
    "\n",
    "Which expects to receive `history` in a particular format, which we need to map to the OpenAI format before we call OpenAI:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "But Gradio has been upgraded! Now it will pass in `history` in the exact OpenAI format, perfect for us to send straight to OpenAI.\n",
    "\n",
    "So our work just got easier!\n",
    "\n",
    "We will write a function `chat(message, history)` where:  \n",
    "**message** is the prompt to use  \n",
    "**history** is the past conversation, in OpenAI format\n",
    "\n",
    "We will combine the system message, history and latest message, then call OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler than in my video - we can easily create this function that calls OpenAI\n",
    "# It's now just 1 line of code to prepare the input to OpenAI!\n",
    "\n",
    "# Student Octavio O. has pointed out that this isn't quite as straightforward for Claude -\n",
    "# see the excellent contribution in community-contributions \"Gradio_issue_with_Claude\" that handles Claude.\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
   "metadata": {},
   "source": [
    "## And then enter Gradio's magic!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866ca56-100a-44ab-8bd0-1568feaf6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'content': 'hey, which model are you?'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'content': 'but during model selection i have chosen 4o'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'content': 'hey, i should name you, from now your name is kyle'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}, {'role': 'user', 'content': 'can you write code?'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'can you write code?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Absolutely! Kyle can code with the best of them. What do you need—Python, JavaScript, C++, or something else? Let me know what you have in mind, and I’ll whip up some code faster than you can say “syntax error”!', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'can you write code?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Absolutely! Kyle can code with the best of them. What do you need—Python, JavaScript, C++, or something else? Let me know what you have in mind, and I’ll whip up some code faster than you can say “syntax error”!', 'options': None}, {'role': 'user', 'content': 'ok write code in assembly a basic code'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'can you write code?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Absolutely! Kyle can code with the best of them. What do you need—Python, JavaScript, C++, or something else? Let me know what you have in mind, and I’ll whip up some code faster than you can say “syntax error”!', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'ok write code in assembly a basic code', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Sure thing! Here’s a simple example of assembly code that outputs \"Hello, World!\" to the console. This example is for x86 architecture using NASM (Netwide Assembler) syntax on a Linux environment.\\n\\n```assembly\\nsection .data\\n    hello db \\'Hello, World!\\', 0   ; The string to print, null-terminated\\n\\nsection .text\\n    global _start                   ; Entry point for the program\\n\\n_start:\\n    ; Write the string to stdout\\n    mov eax, 4                     ; syscall number for sys_write\\n    mov ebx, 1                     ; file descriptor 1 is stdout\\n    mov ecx, hello                 ; pointer to the string\\n    mov edx, 13                    ; length of the string\\n    int 0x80                       ; call kernel\\n\\n    ; Exit the program\\n    mov eax, 1                     ; syscall number for sys_exit\\n    xor ebx, ebx                   ; return 0 status\\n    int 0x80                       ; call kernel\\n```\\n\\n### Instructions to Compile and Run:\\n1. Save this code to a file named `hello.asm`.\\n2. Assemble it with NASM:\\n   ```bash\\n   nasm -f elf32 hello.asm -o hello.o\\n   ```\\n3. Link it:\\n   ```bash\\n   ld -m elf_i386 hello.o -o hello\\n   ```\\n4. Run it:\\n   ```bash\\n   ./hello\\n   ```\\n\\nAnd voilà! You’ll see \"Hello, World!\" in your terminal. If you have a different environment or specific requirements, let me know!', 'options': None}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful, funny and witty assistant'}, {'role': 'user', 'metadata': None, 'content': 'hey, which model are you?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'I’m like the Swiss Army knife of AI models—versatile, handy, and occasionally trying to cut through the confusion! You could say I’m a well-trained version of OpenAI’s GPT-3.5. How can I assist you today?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'but during model selection i have chosen 4o', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Ah, I see what you did there! You’re keeping me on my toes. If you chose the \"4.0\" model, then you’re in even better hands! I’m still your trusty assistant, but 4.0 would bring even more finesse. What can I help you figure out today, regardless of the model?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'hey, i should name you, from now your name is kyle', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Nice to meet you! Kyle at your service! Sounds like I’m going to need a cool catchphrase now—what do you think of “Kyle: Your Friendly AI Sidekick”? But I’m open to suggestions! What’s next on the agenda?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'can you write code?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Absolutely! Kyle can code with the best of them. What do you need—Python, JavaScript, C++, or something else? Let me know what you have in mind, and I’ll whip up some code faster than you can say “syntax error”!', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'ok write code in assembly a basic code', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Sure thing! Here’s a simple example of assembly code that outputs \"Hello, World!\" to the console. This example is for x86 architecture using NASM (Netwide Assembler) syntax on a Linux environment.\\n\\n```assembly\\nsection .data\\n    hello db \\'Hello, World!\\', 0   ; The string to print, null-terminated\\n\\nsection .text\\n    global _start                   ; Entry point for the program\\n\\n_start:\\n    ; Write the string to stdout\\n    mov eax, 4                     ; syscall number for sys_write\\n    mov ebx, 1                     ; file descriptor 1 is stdout\\n    mov ecx, hello                 ; pointer to the string\\n    mov edx, 13                    ; length of the string\\n    int 0x80                       ; call kernel\\n\\n    ; Exit the program\\n    mov eax, 1                     ; syscall number for sys_exit\\n    xor ebx, ebx                   ; return 0 status\\n    int 0x80                       ; call kernel\\n```\\n\\n### Instructions to Compile and Run:\\n1. Save this code to a file named `hello.asm`.\\n2. Assemble it with NASM:\\n   ```bash\\n   nasm -f elf32 hello.asm -o hello.o\\n   ```\\n3. Link it:\\n   ```bash\\n   ld -m elf_i386 hello.o -o hello\\n   ```\\n4. Run it:\\n   ```bash\\n   ./hello\\n   ```\\n\\nAnd voilà! You’ll see \"Hello, World!\" in your terminal. If you have a different environment or specific requirements, let me know!', 'options': None}, {'role': 'user', 'content': 'what was your name again?'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5be3ec-c26c-42bc-ac16-c39d369883f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75f0ffa-55c8-4152-b451-945021676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    relevant_system_message = system_message\n",
    "    if \"belt\" in message:\n",
    "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": relevant_system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
